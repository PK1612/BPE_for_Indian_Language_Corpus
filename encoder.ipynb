{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import kaggle\n",
    "import zipfile\n",
    "import regex as re\n",
    "from utils import Data_Cleaner, BytePairEncoder\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset using kaggle API\n",
    "!kaggle datasets download -d disisbig/hindi-text-short-summarization-corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXCLUSIVE: दिल्ली में डीजल टैक्सियों पर बैन से...</td>\n",
       "      <td>दिल्ली में सुप्रीम कोर्ट के डीज़ल टैक्सियों को...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>जॉर्डन: राष्ट्रपति मुखर्जी ने 86 करोड़ डॉलर के...</td>\n",
       "      <td>जॉर्डन के ऐतिहासिक दौरे पर पहुंचे राष्ट्रपति प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UN में पाकिस्तान की राजदूत मलीहा लोधी ने कराई ...</td>\n",
       "      <td>पाकिस्तानी नेताओं को विवादित और हास्यास्पद बया...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38 देशों में पीएम नरेंद्र मोदी बायोपिक को रिली...</td>\n",
       "      <td>पीएम नरेंद्र मोदी बायोपिक में विवेक ओबेरॉय ने ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13 अगस्त 2011: दिनभर की बड़ी खबरें पढ़ें</td>\n",
       "      <td>देश, दुनिया, महानगर, खेल, आर्थिक और बॉलीवुड मे...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  EXCLUSIVE: दिल्ली में डीजल टैक्सियों पर बैन से...   \n",
       "1  जॉर्डन: राष्ट्रपति मुखर्जी ने 86 करोड़ डॉलर के...   \n",
       "2  UN में पाकिस्तान की राजदूत मलीहा लोधी ने कराई ...   \n",
       "3  38 देशों में पीएम नरेंद्र मोदी बायोपिक को रिली...   \n",
       "4           13 अगस्त 2011: दिनभर की बड़ी खबरें पढ़ें   \n",
       "\n",
       "                                             article  \n",
       "0  दिल्ली में सुप्रीम कोर्ट के डीज़ल टैक्सियों को...  \n",
       "1  जॉर्डन के ऐतिहासिक दौरे पर पहुंचे राष्ट्रपति प...  \n",
       "2  पाकिस्तानी नेताओं को विवादित और हास्यास्पद बया...  \n",
       "3  पीएम नरेंद्र मोदी बायोपिक में विवेक ओबेरॉय ने ...  \n",
       "4  देश, दुनिया, महानगर, खेल, आर्थिक और बॉलीवुड मे...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266607"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 500 characters of the corpus:\n",
      "दिल्ली में सुप्रीम कोर्ट के डीज़ल टैक्सियों को बंद करने के फैसले के बाद हजारों टैक्सी ड्राइवरों की रोजी रोटी पर तो असर पड़ा ही है, लेकिन अब दिल्ली पर एक और नई मुसीबत आ गई है. चुनाव आयोग राजधानी के 13 वार्ड में उपचुनाव करवा रहा है, लेकिन चुनावों से दो हफ्ते पहले चुनाव आयोग में कामकाज ठप्प हो गया है. कमीशन ने किराए पर ली थी डीजल गाड़ियां दरअसल कमीशन ने लगभग सौ गाड़ियां चुनाव के कामकाज को करने के लिए किराए पर लीं, जिनमें सभी डीज़ल से चलने वाली टैक्सी थी. इन्हीं टैक्सियों से चुनाव अधिकारी से लेकर चु\n",
      "\n",
      "Total number of characters in corpus: 1861278\n",
      "Total number of words in corpus: 366465\n",
      "Total number of unique words in corpus: 33830\n"
     ]
    }
   ],
   "source": [
    "articles_text_corpus = ' '.join(df['article'][:1000].values)\n",
    "\n",
    "# Clean the corpus by removing extra whitespace\n",
    "articles_text_corpus = ' '.join(articles_text_corpus.split())\n",
    "\n",
    "# Print the first 500 characters to verify\n",
    "print(\"First 500 characters of the corpus:\")\n",
    "print(articles_text_corpus[:500])\n",
    "\n",
    "# Print some basic statistics\n",
    "print(f\"\\nTotal number of characters in corpus: {len(articles_text_corpus)}\")\n",
    "print(f\"Total number of words in corpus: {len(articles_text_corpus.split())}\")\n",
    "print(f\"Total number of unique words in corpus: {len(set(articles_text_corpus.split()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Cleaner(text):\n",
    "    import regex as re\n",
    "    # Define patterns\n",
    "    pat_remove_English_words = re.compile(r\"\"\" ?[a-zA-Z]+| ?\\p{N}+\"\"\")\n",
    "    pat_non_Devnagari_words = re.compile(r\"\"\" ?[^\\u0900-\\u097F\\s]\"\"\")\n",
    "    pat_keep_Devnagari_words = re.compile(r\"\"\"( ?[\\u0900-\\u097F]+)\"\"\")\n",
    "\n",
    "    # Remove special characters and extra spaces\n",
    "    text = re.sub(pat_remove_English_words, '', text)\n",
    "    text = re.sub(pat_non_Devnagari_words, '', text)\n",
    "    text = re.sub(pat_keep_Devnagari_words, r\" \\1\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "articles_text_corpus = Data_Cleaner(articles_text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of characters in corpus: 1717664\n",
      "Total number of words in corpus: 344533\n",
      "Total number of unique words in corpus: 22704\n",
      "दिल्ली में सुप्रीम कोर्ट के डीज़ल टैक्सियों को बंद करने के फैसले के बाद हजारों टैक्सी ड्राइवरों की रोजी रोटी पर तो असर पड़ा ही है लेकिन अब दिल्ली पर एक और नई मुसीबत आ गई है चुनाव आयोग राजधानी के वार्ड में उपचुनाव करवा रहा है लेकिन चुनावों से दो हफ्ते पहले चुनाव आयोग में कामकाज ठप्प हो गया है कमीशन ने किराए पर ली थी डीजल गाड़ियां दरअसल कमीशन ने लगभग सौ गाड़ियां चुनाव के कामकाज को करने के लिए किराए पर लीं जिनमें सभी डीज़ल से चलने वाली टैक्सी थी इन्हीं टैक्सियों से चुनाव अधिकारी से लेकर चुनावों का जिम्मा संभालने वाले बाकी कर्मचारी भी एक जगह से दूसरी जगह आते जाते थे अचानक चुनावों से ठीक पहले आई इस परेशानी ने दिल्ली चुनाव आयोग का कामकाज ही ठप्प कर दिया है रियायत के लिए की जा सकती है मांग दिल्ली के राज्य चुनाव अधिकारी राकेश मेहता ने इस मुश्किल का रास्ता निकालने के लिए मंगलवार को दिल्ली के पुलिस कमिश्नर और ट्रांसपोर्ट कमिश्नर की बैठक बुलाई है इस बैठक में राज्य चुनाव आयुक्त मई को होने वाले चुनावों को लेकर गाड़ियों की उपलब्धता को लेकर पुलिस और सरकार से समाधान निकालने के लिए भी कहेंगे चुनाव आयोग\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTotal number of characters in corpus: {len(articles_text_corpus)}\")\n",
    "print(f\"Total number of words in corpus: {len(articles_text_corpus.split())}\")\n",
    "print(f\"Total number of unique words in corpus: {len(set(articles_text_corpus.split()))}\")\n",
    "\n",
    "print(articles_text_corpus[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ँंःअआइईउऊऋऌएऐऑओऔकखगघचछजझञटठडढणतथदधनऩपफबभमयरऱलवशषसह़ािीुूृॅेैॉोौ्ॐक़ख़ज़ड़ढ़फ़य़।\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(articles_text_corpus)))\n",
    "initial_vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(initial_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars)}\n",
    "itos = { i:ch for i,ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717664\n"
     ]
    }
   ],
   "source": [
    "tokens = [stoi[c] for c in articles_text_corpus] # convert to a list of integers using custom encoder\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "def merge(ids, pair, idx):\n",
    "  newids = []\n",
    "  i = 0\n",
    "  while i < len(ids):\n",
    "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "      newids.append(idx)\n",
    "      i += 2\n",
    "    else:\n",
    "      newids.append(ids[i])\n",
    "      i += 1\n",
    "  return newids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 4500 # the desired final vocabulary size\n",
    "num_merges = vocab_size - initial_vocab_size\n",
    "ids = list(tokens) # copy so we don't destroy the original list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4426/4426 [31:27<00:00,  2.34it/s]   \n"
     ]
    }
   ],
   "source": [
    "merges = {} # (int, int) -> int\n",
    "for i in tqdm.tqdm(range(num_merges)):\n",
    "  stats = get_stats(ids)\n",
    "  pair = max(stats, key=stats.get)\n",
    "  try:\n",
    "    pair_char = \"\".join([itos[pair[0]], itos[pair[1]]])\n",
    "  except KeyError:\n",
    "    print(f\"pair {pair} not in vocab\")\n",
    "    break\n",
    "  stoi[pair_char] = initial_vocab_size + i\n",
    "  itos[initial_vocab_size + i] = pair_char\n",
    "  idx = initial_vocab_size + i\n",
    "  # print(f\"merging {pair} into a new token {idx}\")\n",
    "  ids = merge(ids, pair, idx)\n",
    "  merges[pair] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens length: 1717664\n",
      "ids length: 444729\n",
      "compression ratio: 3.86X\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"tokens length:\", len(tokens))\n",
    "print(\"ids length:\", len(ids))\n",
    "print(f\"compression ratio: {len(tokens) / len(ids):.2f}X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[269, 519, 92, 1329, 42, 85]\n",
      "ये दिल्ली है मेरे यार\n"
     ]
    }
   ],
   "source": [
    "def encode(text):\n",
    "  # given a string, return list of integers (the tokens)\n",
    "  tokens = [stoi[c] for c in text]\n",
    "  while len(tokens) >= 2:\n",
    "    stats = get_stats(tokens)\n",
    "    pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
    "    if pair not in merges:\n",
    "      break # nothing else can be merged\n",
    "    idx = merges[pair]\n",
    "    tokens = merge(tokens, pair, idx)\n",
    "  return tokens\n",
    "\n",
    "def decode(ids):\n",
    "  text = \"\".join([itos[idx] for idx in ids])\n",
    "  return text\n",
    "\n",
    "print(encode(\"ये दिल्ली है मेरे यार\"))\n",
    "print(decode(encode(\"ये दिल्ली है मेरे यार\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in [269, 519, 92, 1329, 42, 85]:\n",
    "    print(idx,\">>\",itos[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n",
      "4500\n"
     ]
    }
   ],
   "source": [
    "print(len(stoi))\n",
    "print(len(itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mappings\n",
    "with open('stoi.pkl', 'wb') as f:\n",
    "    pickle.dump(stoi, f)\n",
    "\n",
    "with open('itos.pkl', 'wb') as f:\n",
    "    pickle.dump(itos, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('merges.pkl', 'wb') as f:\n",
    "    pickle.dump(merges, f) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
